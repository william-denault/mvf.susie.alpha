% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/multfsusie.R
\name{multfsusie}
\alias{multfsusie}
\title{Multi-modal fSuSiE}
\usage{
multfsusie(
  Y,
  X,
  L = 2,
  pos = NULL,
  prior = "mixture_normal",
  post_processing = c("TI", "smash", "HMM", "none"),
  verbose = TRUE,
  maxit = 100,
  tol = 0.001,
  cov_lev = 0.95,
  min_purity = 0.5,
  L_start = 3,
  filter_cs = TRUE,
  init_pi0_w = 1,
  nullweight = 1,
  control_mixsqp = list(eps = 1e-06, numiter.em = 40, verbose = FALSE),
  thresh_lowcount,
  cal_obj = FALSE,
  greedy = TRUE,
  backfit = TRUE,
  max_SNP_EM = 100,
  gridmult = sqrt(2),
  max_scale = 10,
  max_step_EM = 1,
  cor_small = FALSE,
  filter.number = 10,
  family = "DaubLeAsymm",
  e = 0.001,
  tol_null_prior = 0.001,
  lbf_min = 0.1
)
}
\arguments{
\item{Y}{A list of data frames. Univariate traits are stored in Y$Y_u, with one column per univariate trait (can be set to NULL if no univariate traits are considered). Functional traits are stored in the sublist Y$Y_f, where each element of Y$Y_f is an n by T data frame (T being the number of observation points) (can be NULL if no functional trait is considered).}

\item{X}{A matrix of size n by p containing the covariates.}

\item{L}{The number of effects to fit (default is 2).}

\item{pos}{A list of sampling positions for Y$Y_f entries.
If not provided, the algorithm will assume the columns are evenly spaced.
 If only one entry (e.g., entry 2 out of 3) has non-evenly spaced data,
  you can define pos as follows: pos = list(pos1=NULL, pos2=pos_uneven, pos3=NULL),
   where pos_uneven is a vector containing the sampling positions (assumed to be increasing).}

\item{prior}{Specifies the prior used in functional trait analysis.
The two available choices are "mixture_normal_per_scale" and "mixture_normal" (default).
 Using "mixture_normal" is up to 40\% faster but may lead to slight power loss.}

\item{post_processing}{Character, use "TI" for translation-invariant wavelet estimates,
"HMM" for hidden Markov model (useful for estimating non-zero regions),
or "none" for simple wavelet estimate (not recommended).}

\item{verbose}{If TRUE, the algorithm's progress and a summary of the optimization
settings are printed to the console.}

\item{maxit}{Maximum number of IBSS iterations to perform.}

\item{tol}{A small, non-negative number specifying the convergence tolerance
for the IBSS fitting procedure. The fitting procedure will halt when
 the difference in the variational lower bound, or ELBO
  (the objective function to be maximized), is less than tol.}

\item{cov_lev}{Numeric between 0 and 1, corresponding to the expected
level of coverage of the credible sets. Default is 0.95.}

\item{min_purity}{minimum purity for estimated credible sets}

\item{L_start}{Number of effects initialized at the start of the algorithm.}

\item{filter_cs}{logical, if TRUE filters the credible set (removing low-purity)
cs and cs with estimated prior equal to 0). Set as TRUE by default.}

\item{init_pi0_w}{Starting value of weight on null
component in mixsqp (between 0 and 1).}

\item{nullweight}{numeric value for penalizing likelihood at point mass 0. This number roughly corresponds
to the number of zeros observation you add  (useful in small sample size). Default is 10 as recommended by Stephens in
False discovery rate a new deal. Setting it too low tend lead to adding false discoveries. Setting it too
high may reduce power.}

\item{control_mixsqp}{A list of parameters for the mixsqp function (see mixsqp package).}

\item{thresh_lowcount}{Numeric, used to check if wavelet coefficients have
problematic distribution (very low dispersion even after standardization).
If the median of the absolute value of the distribution of a wavelet coefficient
 is below this threshold, the algorithm discards this wavelet coefficient
  (setting its estimated effect to 0 and its estimated sd to 1).
  Set to 0 by default. Useful when analyzing sparse data from sequence-based
   assays or small samples.}

\item{cal_obj}{Logical, if TRUE computes ELBO for convergence monitoring.}

\item{greedy}{Logical, if TRUE allows greedy search for extra effects
(up to L specified by the user). Set to TRUE by default.}

\item{backfit}{Logical, if TRUE allows discarding effects via backfitting.
Set to TRUE by default. It is advised to keep this as TRUE.}

\item{max_SNP_EM}{maximum number of SNP used for learning the prior. By default, set to 1000. Reducing this may help reduce
the computational time. We advise to keep it at least larger than 50}

\item{gridmult}{numeric used to control the number of components used in the mixture prior (see ashr package
for more details). From the ash function:  multiplier by which the default grid values for mixed differ from one another.
 (Smaller values produce finer grids.). Increasing this value may reduce computational time.}

\item{max_scale}{numeric, define the maximum of wavelet coefficients used in the analysis (2^max_scale).
Set 10 true by default.}

\item{max_step_EM}{max_step_EM}

\item{cor_small}{logical set to FALSE by default. If TRUE used the Bayes factor from Valen E Johnson JRSSB 2005 instead of Wakefield approximation for Gen Epi 2009
The Bayes factor from Valen E Johnson JRSSB 2005 tends to have better coverage in small sample sizes. We advise using this parameter if n<50}

\item{filter.number}{see documentation of wd from wavethresh package}

\item{family}{see documentation of wd from wavethresh package}

\item{e}{Threshold value to avoid computing posterior probabilities
that have low alpha values. Set to 0 to compute the entire posterior.
Default value is 0.001.}

\item{lbf_min}{numeric  discard low purity cs in the IBSS fitting procedure if the largest log Bayes factors is lower than this value}
}
\description{
Implementation of the Multi-modal fSuSiE method.
}
\details{
Implementation of the multfSuSiE method.
}
\examples{
library(mvf.susie.alpha)
set.seed(1)

N <- 100 # Sample size
P <- 100 # Number of SNPs
L <- 2 # Number of effects
list_lev_res <- list(5, 6)
# Two functional phenotypes, one of length 2^5 and one of length 2^6
n_univ <- 3 # 3 univariate phenotypes
eff <- list()
for (l in 1:L) { # Simulate the multi-trait effect
  eff[[l]] <- simu_effect_multfsusie(list_lev_res=list_lev_res,
                                     n_univ=n_univ, output_level=2)
}

Y_f1 <- matrix(rnorm((2^list_lev_res[[1]]) * N, sd=1), nrow=N)
Y_f2 <- matrix(rnorm((2^list_lev_res[[2]]) * N, sd=1), nrow=N)
Y_u <- matrix(rnorm(n_univ * N, sd=1), nrow=N)
# Genotype matrix
G <- matrix(sample(c(0, 1, 2), size=N*P, replace=TRUE), nrow=N, ncol=P)

true_pos <- sample(1:ncol(G), L) # Actually causal columns/SNPs

for (i in 1:N) {
  for (l in 1:L) {
    Y_f1[i,] <- Y_f1[i,] + eff[[l]]$func_effect[[1]]$sim_func * G[i, true_pos[[l]]]
    Y_f2[i,] <- Y_f2[i,] + eff[[l]]$func_effect[[2]]$sim_func * G[i, true_pos[[l]]]
    Y_u[i,]  <- Y_u[i,]  + eff[[l]]$univ_effect * G[i, true_pos[[l]]]
  }
}

Y_f <- list(Y_f1, Y_f2)
Y <- list(Y_f=Y_f, Y_u=Y_u) # Preparing data

pos <- list(pos1=1:ncol(Y$Y_f[[1]]), pos2=1:ncol(Y$Y_f[[2]]))
# If your signal is sampled between 1 and 64

m1 <- multfsusie(Y=Y, X=G, pos=pos, L=3)
print(m1$cs) # Credible sets
print(true_pos)

par(mfrow=c(2,1))
plot(m1$fitted_func[[1]][[1]], type="l", col="green",
main="Estimated function for the first marker", ylab="y")
lines(eff[[2]]$func_effect[[1]]$sim_func)
lines(m1$cred_band[[1]][[1]][1,], lty=2, col="darkgreen")
lines(m1$cred_band[[1]][[1]][2,], lty=2, col="darkgreen")

plot(m1$fitted_func[[1]][[2]], type="l", col="green",
main="Estimated function for the second marker", ylab="y")
lines(eff[[2]]$func_effect[[2]]$sim_func)
lines(m1$cred_band[[1]][[2]][1,], lty=2, col="darkgreen")
lines(m1$cred_band[[1]][[2]][2,], lty=2, col="darkgreen")

# A bit slower but useful for properly estimating the support of the effect
m1 <- multfsusie(Y=Y, X=G, pos=pos, L=3, post_processing = "HMM")

plot(m1$fitted_func[[1]][[1]], type="l", col="green",
 main="Estimated function for the first marker", ylab="y")
lines(eff[[2]]$func_effect[[1]]$sim_func)
abline(h=0)
lines(m1$lfsr[[1]]$est_lfsr_functional[[1]], lty=2, col="darkgreen")
plot(m1$fitted_func[[1]][[2]], type="l", col="green",
main="Estimated function for the first marker", ylab="y")
lines(eff[[2]]$func_effect[[2]]$sim_func)
abline(h=0)
lines(m1$lfsr[[1]]$est_lfsr_functional[[2]], lty=2, col="darkgreen")
}
