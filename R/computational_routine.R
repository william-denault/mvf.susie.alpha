#'@title Function to fit entry-wise lm on tensor regression
#'
#'@param l  wavelet coefficient index
#'@param j  covariate index
#'@param xi condition index
#'@param Y observed tensor
#'@param X observed covariate
#' @export
parse_lm_fit <- function(j,l,xi, v1,Y,X)
{

  out <- fast_lm(cbind(v1,X[,j]),Y[,l,xi])
  return(c(out$be[2,1],
           sqrt(
             var(out$residuals)/sum(
               (X[,j]-mean(X[,j]))^2)
           )
  )
  )
}



#' @title Regress column l and condition of Y on column j of X
#'
#' @description Add description here.
#'
#' @param Y  tensor phenotype, matrix of size N by size J by xi. The underlying algorithm uses wavelets that assume that J is of the form J^2. If J is not a power of 2, susiF internally remaps the data into a grid of length 2^J
#'
#' @param X matrix of size n by p in
#'
#' @param v1 vector of 1 of length n
#'
#' @return list of two tensor of size pxTx xi of 2 containing the regression coefficient and standard error
#'
#' @importFrom stats var
#'
#' @export
#'


cal_Bhat_Shat_tensor  <- function(Y, X, v1)
{
  Bhat  <- list()
  Shat  <- list()
  h <- 1 # looping index
  #need to parse by variable  (most inside loop) then by wave coef then by condition
  for (xi in 1:dim(Y)[3])
  {
    for ( l in 1:dim(Y)[2])
    {
      out <-  do.call( cbind,lapply( 1:dim(X)[2], function(j) parse_lm_fit( j=j,l=l,xi=xi,v1=v1, Y=Y, X=X ) ) )
      Bhat[[h]]  <- out[1,]
      Shat[[h]]  <- out[2,]
      h <- h+1
    }
  }

  tens_Bhat <- array( do.call(c, Bhat), dim = c( ncol(X),dim(Y)[2], dim(Y)[3]) )
  tens_Shat <- array( do.call(c, Shat), dim = c( ncol(X),dim(Y)[2], dim(Y)[3]) )

  out <- list( tens_Bhat = tens_Bhat,
               tens_Shat = tens_Shat)
  return(out)
}




#' @title Regress different marks of Y   on X nxp
#'
#' @description regression coefficients (and sd) of the column wise regression
#'
#' @param Y a list of two, Y_u containning a N by J data frame of univariate phneotype and Y_f a k list contains a list of functionnal phenoytpes
#'
#' @param X matrix of size N by P in
#'
#' @return a nested list list of two
#'
#' \item{res_uni}{ list of two Bhat: matrix pxJ regression coefficient, Bhat[j,t] corresponds to regression coefficient of the t univariate phneotype
#'  on X[,j]; Shat is the matrix of the corresponding standard error }
#'
#' \item{res_f}{ a list of k in which each element contains Bhat and Shat matrix (see description in item res_uni}
#'
#' @export


cal_Bhat_Shat_multfsusie <- function( Y,X,v1,list_indx_lst=NULL)
{

  if(is.null(Y$Y_u)){
    res_uni <- NULL
  }else{
    res_uni   <- susiF.alpha::cal_Bhat_Shat(Y$Y_u,X,v1)
  }

  if(is.null(Y$Y_f)){
    res_f <- NULL
  }else{
    res_f <- lapply(1:length(Y$Y_f),  function(k)  cal_Bhat_Shat(Y$Y_f[[k]], X,v1 )
                      )
  }

 res  <- list( res_uni = res_uni,
               res_f   = res_f)

}




#' @title Method to fit mash
#'
#' @description Method to fit mash
#'
#' @param Bhat  matrix of the regression coefficient (MLE)
#' @param Shat  matrix of standard error
#' @param data.driven logical, if TRUE use data driven covariance matrix procedure for fitting mash otherwise uses  cov_canonical method mashr. Set as TRUE by default
#'
#' @return a mash object
#'
#' @importFrom mashr mash_set_data
#' @importFrom mashr mash_1by1
#' @importFrom mashr get_significant_results
#' @importFrom mashr cov_pca
#' @importFrom mashr cov_ed
#' @importFrom mashr cov_canonical
#' @importFrom mashr mash
#'
#' @export
#'


basic_mash_fit <- function (Bhat, Shat, data.driven=TRUE, verbose=FALSE)
{
  data   = mash_set_data( Bhat,  Shat)

  if( data.driven)
  {
    m.1by1 = mash_1by1(data)
    strong = get_significant_results(m.1by1,0.05)
    if( !(length(strong)==0))
    {
      U.pca  = cov_pca(data,
                       npc=length(strong),
                       subset=strong
      )
      #Problem with TPCa being NAN
      U.ed   = cov_ed(data, U.pca, subset=strong)
      U.c    = cov_canonical(data)
      m      = mash(data, c(U.c,U.ed),verbose = verbose)
    }else{
      U.c    = cov_canonical(data)
      m      = mash(data, c(U.c),verbose = verbose)
    }
  }else{
    U.c    = cov_canonical(data)
    m      = mash(data, c(U.c),verbose = verbose)
  }


  return(m)
}





#' @title Fit mash for a given set of wavelet coefficients
#'
#' @description Fit mash for a given set of wavelet coefficients
#'
#' @param tens_marg list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#'
#' @param s scale of interest
#'
#' @param data.driven logical, if TRUE use data driven covariance matrix procedure for fitting mash otherwise uses  cov_canonical method mashr. Set as TRUE by default
#'
#' @param indx_list list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution
#'
#' @return a mash object
#'
#' @export
#'


fit_mash_level <- function(tens_marg, s, indx_lst, data.driven=TRUE,verbose=FALSE)
{



  Bhat <- cbind_3Darray( tens_marg$tens_Bhat[,indx_lst[[s]],] )
  Shat <- cbind_3Darray( tens_marg$tens_Shat[,indx_lst[[s]],] )


  m <- basic_mash_fit(Bhat, Shat, data.driven = data.driven,verbose=verbose)

}


#' @title Compute Log-Bayes Factor of given scale and covariate for multivariate wavelet regression
#'
#' @description   Compute Log-Bayes Factor of given scale and covariate for multivariate wavelet regression
#'
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#'
#' @param s scale of interest
#'
#' @param j  covariate of interest
#'
#' @param indx_list List generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#'
#' @return The log-Bayes factor of the given scale and covariate
#'
#' @export
#'

cal_lbf_mvfsusie_level <-  function(G_prior, tens_marg,s ,j , indx_lst)
{


  Bhat   <-   matrix(tens_marg$tens_Bhat[j,indx_lst[[s]],],ncol = dim(tens_marg$tens_Bhat)[3])
  Shat   <-   matrix(tens_marg$tens_Shat[j,indx_lst[[s]],],ncol = dim(tens_marg$tens_Bhat)[3])
  data   <-   mash_set_data( Bhat,  Shat)
  m      <-   G_prior[[s]]

  loglik      <-  sum (mash_compute_vloglik(m,data))
  null_loglik <-  mvfsusie_compute_null_loglik(Bhat,Shat)
  lbf         <-   loglik -null_loglik

  return(lbf)
}

#' @title Compute Log-Bayes Factor of a given   covariate for multivariate wavelet regression
#'
#' @description   Compute Log-Bayes Factor of a given   covariate for multivariate wavelet regression
#'
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#'
#' @param s scale of interest
#'
#' @param j  covariate of interest
#'
#' @param indx_list List generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#'
#' @return The log-Bayes factor for the considered covariate.
#'
#' @export
#'

cal_lbf_cov_mvsusie <- function(G_prior,tens_marg,s,j,indx_lst)
{
  #sum over the level specific Bayes Factor
  out <- do.call(sum,
                 lapply ( 1:length(indx_lst),
                          function(s) cal_lbf_mvfsusie_level (G_prior,
                                                              tens_marg,
                                                              s,
                                                              j,
                                                              indx_lst
                                                              )
                        )
                )
  return(out)
}


#' @title Compute Log-Bayes Factor for multivariate wavelet regression
#'
#' @description  Compute Log-Bayes Factor for multivariate wavelet regression using a scale specific mash prior
#'
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#'
#' @param indx_list List generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#'
#' @return The log-Bayes factor for each covariate.
#'
#' @export
#'
log_BF_tens <- function( G_prior, tens_marg, indx_lst){


  out <-  do.call(c,
                  lapply( 1:dim( tens_marg$tens_Bhat)[1], #number of covariate
                       function(j) cal_lbf_cov_mvsusie (G_prior,
                                                        tens_marg,
                                                        s,
                                                        j,
                                                        indx_lst
                                                        )
                       )
               )

 return(out)
}


#' @title Compute log likelihood of multivariate gaussian model under the null
#'
#' @description  Compute log likelihood of multivariate gaussian model under the null
#'
#' @param Bhat a matrix (n_wavelet_coef x n_cond)  of MLE mean estimate
#'
#' @param Shat a matrix (n_wavelet_coef x n_cond)  of MLE sd estimate
#'
#' @return The log likelihood
#'
#' @export
#'
mvfsusie_compute_null_loglik <- function(Bhat,Shat)
{

 out <- do.call(sum,
                lapply( 1:nrow(Bhat),
                        function(i) dmvnorm(x=(Bhat[i,]),
                                            mean= rep(0,length(Bhat[i,])),
                                            sigma= diag((Shat[i,])^2),
                                            log=TRUE)
                        )
                )
 return(out)


}






#' @title EM algorithm to select mixture weight in a  Empirical Bayes way for multivariate SuSiE
#'
#' @description Select the mixture weight by maximizing the marginal likelihood
#'
#'
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#'
#' @param indx_list List generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#'
#' @param max_step numeric, maximum number of EM iteration
#'
#'
#' @param espsilon numeric, tolerance EM algorithm
#'
#' @return
#'\item{tpi_k}{ fitted mixture proportion}
#'\item{lBF}{ log Bayes Factor}
#'
#' @export
#'
EM_pi_mvfsusie <- function(G_prior,tens_marg, indx_lst,
                            max_step = 100,
                            espsilon = 0.0001){

  #static parameters
  Lmat  <-  L_mixsq_mvfsusie(G_prior, tens_marg, indx_lst)
  J <- dim(tens_marg$tens_Bhat)[1]

  oldloglik <-0
  newloglik <-1

  zeta <- rep(1/J,J) #assignation initial value
  k <- 1 #counting the number of iteration

  lBF <- log_BF_tens  ( G_prior, tens_marg, indx_lst)

  while( k <max_step &  abs(newloglik-oldloglik)>=espsilon)
  {
    # E step----
    oldloglik <- cal_lik_mvfsusie (lBF,zeta)
    zeta      <- cal_zeta_mvfsusie(lBF)

    # M step ----
    tpi_k   <- m_step_mvfsusie(Lmat,zeta,indx_lst)
    G_prior <- update_prior_weight_mvfsusie(G_prior,tpi_k)

    lBF <- log_BF_tens  ( G_prior, tens_marg, indx_lst)
    newloglik <- cal_lik_mvfsusie(lBF,zeta)
    k <- k+1
    #newloglik
    # oldloglik
    # lBF
  }

  out <- list(tpi_k = tpi_k,lBF = lBF)
  class(out) <- c("EM_pi_mvfsusie","list")
  return(out)
}

#'@title Compute likelihood matrix for mixsqp
#'
#' @description Compute likelihood matrix for mixsqp
#'
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#'
#' @param indx_list List generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#'
#' @return See L argument mixsqp package mixsqp function
#'
#' @export
L_mixsq_mvfsusie <- function(G_prior, tens_marg, indx_lst)
{
   L <- lapply( 1:length(indx_lst), function(s) L_mixsq_mvfsusie_scale(G_prior, tens_marg, indx_lst,s))
   return(L)
}


#'@title Compute likelihood matrix for mixsqp
#'
#' @description Compute likelihood matrix for mixsqp
#'
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#'
#' @param indx_list List generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#'
#' @param s scale of interest
#'
#' @return a matrix of scale specific log likelihood value
#' @export
L_mixsq_mvfsusie_scale <- function(G_prior, tens_marg, indx_lst,s)
{
  grid   <-  get_grid (G_prior , s)
  Ulist  <-  get_Ulist (G_prior , s)

  Bhat   <-  cbind_3Darray(tens_marg$tens_Bhat[,indx_lst[[s]],])
  Shat   <-  cbind_3Darray(tens_marg$tens_Shat[,indx_lst[[s]],])
  data   <-  mash_set_data( Bhat,  Shat)
  xUlist <-  utils::getFromNamespace("expand_cov", "mashr")(Ulist,grid,usepointmass=TRUE)



  L_mat  <-  utils::getFromNamespace("calc_relative_lik_matrix", "mashr")(data = data, xUlist) # allow using unexported function

  return(L_mat$loglik_matrix)
}




#' @title Compute M step in the weighted mashr problem
#'
#' @description Add description here.
#'
#' @param L output of  \code{\link{L_mixsq_mvfsusie}} function
#'
#' @param zeta assignment probabilities for each covariate
#'
#' @param indx_list list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution, used only with class  mixture_normal_per_scale
#'
#' @return a list of proportion (class pi_mixture_normal)
#'
#' @export

m_step_mvfsusie <- function(L, zeta, indx_lst, ...)
{
  #setting the weight to fit the weighted ash problem


  out <- lapply(1:length(indx_lst) ,
                function(s) scale_m_step_mvfsusie(L,s,zeta,indx_lst)
  )

  return(out)

}

#'@title Subroutine to compute M step in the weighted mash problem for normal mixture prior per scale
#'
#' @description  Subroutine to compute M step in the weighted mash
#'
#' @param L output of the L_mixsqp.mixture_normal_per_scale function
#'
#' @param s scale
#'
#' @param zeta assignment probabilities for each covariate
#'
#' @param indx_list list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution, used only with class  mixture_normal_per_scale
#'
#' @return a vector of proportion for the scale s
#'
#' @importFrom mixsqp mixsqp
#'
#' @export
scale_m_step_mvfsusie <- function(L,s,zeta, indx_lst)
{
  w <- rep(zeta,length(indx_lst[[s]] ))
  tlength <- dim(L[[s]])[2]-1
  mixsqp_out <- mixsqp( L[[s]] ,
                        w,
                        #x0 = c(1, rep(1e-30,  tlength )),
                        log=TRUE ,
                        control = list(
                          eps = 1e-6,
                          numiter.em = 20,
                          verbose=FALSE
                        )
  )

  out <- mixsqp_out$x
  return( out)

}



#' @title Compute assignment probabilities from log Bayes factors
#'
#' @description  Compute assignment probabilities from log Bayes factors
#'
#' @param lBF vector of log Bayes factors

cal_zeta_mvfsusie <- function(lBF)
{
  out <- exp(lBF - max(lBF ) ) /sum( exp(lBF - max(lBF ) ))
  return(out)
}


#' @title Compute likelihood for the weighted mash problem
#'
#' @description Compute likelihood for the weighted mash problem
#'
#' @param lBF vector of log Bayes factors
#'
#' @param zeta assignment probabilities
#'
#' @return Likelihood value
#'
#' @export
#'
cal_lik_mvfsusie <- function(lBF,zeta)
{
  out <- sum( zeta*exp(lBF - max(lBF ) ))
  return(out)
}


#' @title Compute posterior quantities of tensor regression for a given scale and a given covariate
#'
#' @description Compute posterior  quantities  of the tensor regression  using a scale specific mash prior
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#' @param indx_list list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution, used only with class  mixture_normal_per_scale
#' @param s the scale of interest
#' @param j the covariate of interest
#'
#' @export

get_post_effect <- function( G_prior, tens_marg, indx_lst, s,j) {
  Bhat   <-   matrix(tens_marg$tens_Bhat[j,indx_lst[[s]],],
                     ncol = dim(tens_marg$tens_Bhat)[3]
  )
  Shat   <-   matrix(tens_marg$tens_Shat[j,indx_lst[[s]],],
                     ncol = dim(tens_marg$tens_Bhat)[3]
  )
  data   <-   mash_set_data( Bhat,  Shat)

  m2     <-   mash_compute_posterior_matrices( G_prior[[s]],
                                               data
  )

  return(m2)
}





#' @title Compute posterior quantities of tensor regression for a given scale
#'
#' @description Compute posterior  quantities  of the tensor regression  using a scale specific mash prior
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#' @param indx_list list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution, used only with class  mixture_normal_per_scale
#' @param s the scale of interest
#'
#' @export
get_post_level <- function( G_prior, tens_marg, indx_lst,s, all=FALSE)
{
  res <-  lapply( 1:ncol(X),function(j) get_post_effect( G_prior, tens_marg, indx_lst, s,j) )

  if(!all)
  {
    PosteriorMean_level <- abind(
                                  lapply( 1:dim(tens_marg$tens_Bhat)[1],
                                          function(j) res[[j]]$PosteriorMean),
                                  along=0
                                )

    Posteriorsd_level   <- abind(
                                  lapply( 1:dim(tens_marg$tens_Bhat)[1],
                                   function(j) res[[j]]$PosteriorSD),
                                  along=0
                                )
    out <- list(PosteriorMean_level = PosteriorMean_level,
                Posteriorsd_level   = Posteriorsd_level
                )
  }else{
    PosteriorMean_level <-  abind(
                                  lapply( 1:dim(tens_marg$tens_Bhat)[1],
                                         function(j) res[[j]]$PosteriorMean
                                         ),
                                   along=0
                                  )

    Posteriorsd_level   <-  abind(
                                  lapply( 1:dim(tens_marg$tens_Bhat)[1],
                                          function(j) res[[j]]$PosteriorSD
                                          ),
                                   along=0
                                   )

    lfdr_level          <-  abind(
                                    lapply( 1:dim(tens_marg$tens_Bhat)[1],
                                           function(j) res[[j]]$lfdr
                                           ),
                                   along=0
                                   )

    NegativeProb_level  <-  abind(
                                  lapply( 1:dim(tens_marg$tens_Bhat)[1],
                                         function(j) res[[j]]$NegativeProb
                                   ),
                                   along=0)

    lfsr_level          <-  abind(lapply( 1:dim(tens_marg$tens_Bhat)[1],
                                          function(j) res[[j]]$lfsr
                                          ),
                                   along=0
                                  )

    out <- list(PosteriorMean_level = PosteriorMean_level,
                Posteriorsd_level   = Posteriorsd_level,
                lfdr_level          = lfdr_level ,
                NegativeProb_level  = NegativeProb_level,
                lfsr_level          = lfsr_level
               )
  }

  return( out)
}




#' @title Compute posterior quantities of tensor regression
#'
#' @description Compute posterior mean and sd of the tensor regression  using a scale specific mash prior
#' @param G_prior a scale specific mash prior
#'
#' @param tens_marg a list of tensor of marginal association generated by \code{cal_Bhat_Shat_tensor}
#' @param all logical, if set as FALSE the function a=only return posterior mean and SD. If set as true return  lfdr, NegativeProb and lfsr. Set to FALSE by default
#' @export
get_post_tens <- function(G_prior, tens_marg, indx_lst, all =FALSE)
{


  if ( !all){
    tt <- lapply( 1: length(indx_lst),
                  function(s)  get_post_level(G_prior, tens_marg, indx_lst,s, all =all)
    )


    post_mean_tens <- array(NA,dim =dim(tens_marg$tens_Bhat))
    post_sd_tens <- array(NA,dim =dim(tens_marg$tens_Bhat))
    for ( s in 1: 1: length(indx_lst)){
      post_mean_tens[ ,indx_lst[[s]],] <- tt[[s]]$PosteriorMean_level
      post_sd_tens  [ ,indx_lst[[s]],] <- tt[[s]]$Posteriorsd_level

    }

    out <- list(post_mean_tens = post_mean_tens,
                post_sd_tens   =   post_sd_tens
                )
  }else{


         tt <- lapply( 1: length(indx_lst),
                       function(s)  get_post_level(G_prior, tens_marg, indx_lst,s, all =all)
                      )


        post_mean_tens    <- array(NA,dim =dim(tens_marg$tens_Bhat))
        post_sd_tens      <- array(NA,dim =dim(tens_marg$tens_Bhat))
        lfdr_tens         <- array(NA,dim =dim(tens_marg$tens_Bhat))
        NegativeProb_tens <- array(NA,dim =dim(tens_marg$tens_Bhat))
        lfsr_tens         <- array(NA,dim =dim(tens_marg$tens_Bhat))
        for ( s in 1: 1: length(indx_lst)){
          post_mean_tens   [ ,indx_lst[[s]],] <- tt[[s]]$PosteriorMean_level
          post_sd_tens     [ ,indx_lst[[s]],] <- tt[[s]]$Posteriorsd_level
          lfdr_tens        [ ,indx_lst[[s]],] <- tt[[s]]$lfdr_level
          NegativeProb_tens[ ,indx_lst[[s]],] <- tt[[s]]$NegativeProb_level
          lfsr_tens        [ ,indx_lst[[s]],] <- tt[[s]]$lfsr_level

        }
        out <- list(
                   post_mean_tens    = post_mean_tens,
                   post_sd_tens      = post_sd_tens,
                   lfdr_tens         = lfdr_tens,
                   NegativeProb_tens = NegativeProb_tens,
                   lfsr_tens         = lfsr_tens
                    )
  }


 return( out)

}
#get_post_mean_tens

#get_post_sd_tens





#' @title EM algorithm to select mixture weight in a  Empirical Bayes way for multSuSiE
#'
#' @description Select the mixture weight by maximizing the marginal likelihood
#'
#'
#' @param G_prior a multfsusie_prior
#'
#' @param effect_estimate a list of marginal association generated by \code{cal_Bhat_Shat_multsusie}
#'
#' @param  list_indx_lst List of lists generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#'
#' @param max_step numeric, maximum number of EM iteration
#'
#'
#' @param espsilon numeric, tolerance EM algorithm
#'
#' @return
#'\item{tpi_k}{ fitted mixture proportion}
#'\item{lBF}{ log Bayes Factor}
#'
#' @export
#'
EM_pi_multsusie <- function(G_prior,effect_estimate, list_indx_lst,
                           max_step = 100,
                           espsilon = 0.0001)
{


   L_mat  <- L_mixsq_multsusie (G_prior, effect_estimate, list_indx_lst)
   if( !is.null(effect_estimate$res_uni)){
     J <- nrow( effect_estimate$res_uni$Bhat)
   }else{
     J <- nrow( effect_estimate$res_f[[1]]$Bhat)
   }


   #dynamic parameters
   tpi_k = get_pi_G_prior(G_prior)
   oldloglik <-0
   newloglik <-1

   zeta <- rep(1/J,J) #assignation initial value
   k <- 1 #counting the number of iteration

  lBF <- log_BF(G_prior,effect_estimate ,list_indx_lst)

  while( k <max_step &  abs(newloglik-oldloglik)>=espsilon)
  {
    # E step----
    oldloglik <- susiF.alpha::cal_lik(lBF,zeta)
    zeta      <- cal_zeta(lBF)

    # M step ----
    tpi_k   <- m_step_multsusie(L_mat,zeta,list_indx_lst)
    G_prior <- update_prior(G_prior,tpi_k)

    lBF <- log_BF(G_prior,effect_estimate ,list_indx_lst)
    newloglik <- susiF.alpha::cal_lik(lBF,zeta)
    k <- k+1

  }

  out <- list(tpi_k = tpi_k,lBF = lBF)
  class(out) <- c("EM_pi_multfsusie","list")
  return(out)
}



#' @title Compute Log-Bayes Factor for univariate regression with ash prior
#'
#' @description Compute Log-Bayes Factor
#'
#' @param G_prior ash object
#'
#' @param Bhat p numerical vector of regression coefficients;
#'
#' @param Shat p numerical of standard errors;
#' @return  The log-Bayes factor for each covariate.
#'
#' @export

log_BFu <- function (G_prior, Bhat, Shat, ...) {

    m    <- G_prior
    tt   <- rep(0,length(Shat))
    pi_k <- m$fitted_g$pi
    sd_k <- m$fitted_g$sd

    # Speed Gain: could potential skip the one that are exactly zero.
    for (k in 1:length(m$fitted_g$pi)){
      tt <- tt + pi_k[k] * dnorm(Bhat ,sd = sqrt(sd_k[k]^2 + Shat ^2))
    }

    out <-  (log(tt) - dnorm(Bhat ,sd = Shat ,log = TRUE))
  return(out)
}



#' @title Compute Log-Bayes Factor for a multiple f susie regression model
#' @description Compute Log-Bayes Factor
#'
#' @param G_prior a multfsusie_prior
#'
#' @param effect_estimate regression coefficients generated by \link{\code{cal_Bhat_Shat_multfsusie}}
#'
#' @param  list_indx_lst List of lists generated by \code{\link{gen_wavelet_indx}}
#'   for the given level of resolution
#' @return  The log-Bayes factor for each covariate.
#'
#' @export
log_BF.multfsusie_prior <- function( G_prior,effect_estimate ,list_indx_lst)
{
  if( is.null(G_prior$G_prior_u)){
    u_logBF <- rep(0,nrow(effect_estimate$res_f[[1]]$Bhat  ))
  }else{
    u_logBF <-  lapply(1:ncol(effect_estimate$res_uni$Bhat),
                       function(k)
                         log_BFu(G_prior$G_prior_u[[k]],
                                 Bhat=  effect_estimate$res_uni$Bhat[,k] ,
                                 Shat= (effect_estimate$res_uni$Shat[,k])
                         )
    )
    u_logBF <- apply(do.call(rbind, u_logBF),2,sum)
  }
  if(is.null(G_prior$G_prior_f)){
    f_logBF <- rep(0,nrow(effect_estimate$res_uni[[1]] ))
  }else{
    f_logBF <- lapply( 1: length(G_prior$G_prior_f) ,function( k)
      susiF.alpha::log_BF(G_prior$G_prior_f[[k]],
                          Bhat = effect_estimate$res_f[[k]]$Bhat,
                          Shat = effect_estimate$res_f[[k]]$Shat,
                          indx_lst= list_indx_lst[[k]]
      )
    )
    f_logBF <- apply(do.call(rbind, f_logBF),2,sum)
  }

  out <- f_logBF+u_logBF
  return(out)

}




L_mixsq_multsusie <- function(G_prior, effect_estimate, list_indx_lst) {

  if(is.null(G_prior$G_prior_u)){
    L_mat_u <- NULL
  }else{
    L_mat_u <- lapply( 1: length(G_prior$G_prior_u) ,function( k)
                  L_mixsq_u(G_prior$G_prior_u[[k]],
                          Bhat = effect_estimate$res_u$Bhat[,k],
                          Shat = effect_estimate$res_u$Shat[,k]
                          )
                        )

  }
  if(is.null(G_prior$G_prior_f)){
    L_mat_f <- NULL
  }else{
    L_mat_f <- lapply( 1: length(G_prior$G_prior_f) ,function( k)
      susiF.alpha::L_mixsq(G_prior$G_prior_f[[k]],
                           Bhat = effect_estimate$res_f[[k]]$Bhat,
                           Shat = effect_estimate$res_f[[k]]$Shat,
                           indx_lst= list_indx_lst[[k]]
      )
    )

  }
  L_mat <- list(L_mat_u=L_mat_u,
                L_mat_f=L_mat_f)
  attr(L_mat,"class") <- "lik_multfsusie"
return(L_mat)
}

#' @title Compute Log-Bayes Factor for univariate regression with ash prior
#'
#' @description Compute Log-Bayes Factor
#'
#' @param G_prior ash object
#'
#' @param Bhat p numerical vector of regression coefficients;
#'
#' @param Shat p numerical of standard errors;
#' @return See L argument mixsqp package mixsqp function
#'
#' @export
L_mixsq_u <- function(G_prior, Bhat, Shat){
  m     <-  (G_prior )
  sdmat <- sqrt(outer(c(Shat ^2), m$fitted_g$sd^2,"+"))
  L     <- (
    dnorm(
      outer(
        c(Bhat),
        rep(0,length(m$fitted_g$sd)),
        FUN="-"
      )/sdmat,
      log=TRUE
    ) -log(sdmat )
  )
  class(L) <- "lik_mixture_normal"
  return(L)
}




#' @title Compute M step in the weighted ash  problem
#'
#' @description Add description here.
#'
#' @param L output of  \code{\link{L_mixsq_multsusie}} function
#'
#' @param zeta assignment probabilities for each covariate
#'
#' @param indx_list list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution, used only with class  mixture_normal_per_scale
#'
#' @return a list of proportion (class pi_mixture_normal)
#'
#' @export

m_step_multsusie <- function(L_mat, zeta, list_indx_lst, ...)
{
  #setting the weight to fit the weighted ash problem
  if (is.null(L_mat$L_mat_u)){
    est_pi_u <- NULL
  }else{
    est_pi_u <- lapply(1:length(L_mat$L_mat_u) ,
                       function(k) m_step_u (L_mat$L_mat_u[[k]],
                                          zeta )
    )
  }
  if (is.null(L_mat$L_mat_f)){
    est_pi_f <- NULL
  }else{
    est_pi_f <- lapply(1:length(L_mat$L_mat_f) ,
                       function(k) m_step(L_mat$L_mat_f[[k]],
                                          zeta,
                                          list_indx_lst[[k]]
                                          )
                      )
  }

  out <- list(est_pi_u= est_pi_u,
              est_pi_f = est_pi_f
  )
  attr(out, "class") <- "pi_multfsusie"
  return(out)

}






#' @title Compute M step in the weighted ash  problem for univariate regression
#'
#' @description Add description here.
#'
#' @param L output of  \code{\link{L_mixsq_multsusie}} function
#'
#' @param zeta assignment probabilities for each covariate
#'
#' @param indx_list list generated by \code{\link{gen_wavelet_indx}} for the given level of resolution, used only with class  mixture_normal_per_scale
#'
#' @return a list of proportion (class pi_mixture_normal)
#'
#' @export

m_step_u <- function  (L, zeta , ...)
{
  w <-zeta # setting the weight to fit the weighted ash problem
  tlength <- ncol(L) - 1
  mixsqp_out <- mixsqp(L,
                       w,
                       log = TRUE,
                       x0 = c(1,rep(1e-30,tlength)), # put starting point close to sparse solution
                       control = list(
                         eps = 1e-6,
                         numiter.em = 20,
                         verbose = FALSE
                       )
  )
  out <- mixsqp_out$x
  class(out) <-  "pi_mixture_normal"
  return(out)
}

#' @title Compute posterior mean for univariate regression
#' @description Compute posterior mean for univariate regression
#' @param Bhat  a vector of mean estimate
#' @param Bhat  a vector of sd estimate
get_post_mean_u <- function(G_prior, Bhat, Shat)
{
  data <-  set_data(Bhat  ,Shat  )
  return(postmean(get_fitted_g(G_prior),data))
}


#' @title Compute posterior sd for univariate regression
#' @description Compute posterior sd for univariate regression
#' @param Bhat  a vector of mean estimate
#' @param Bhat  a vector of sd estimate
get_post_sd_u <- function(G_prior, Bhat, Shat)
{
  data <-  set_data(Bhat  ,Shat  )
  return(postsd(get_fitted_g(G_prior),data))
}

